{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! This is a simple notebook to demo Small-Fry usage. If you have any questions, please feel free to contact [tginart](https://github.com/tginart).\n",
    "\n",
    "For the purposes of this demo, we will be compressing 1,000 rows (words) from the offical [Wiki Gigawords GloVe embeddings]. Our demo embeddings are light-weight enough to keep within the code repository.  \n",
    "\n",
    "Although Small-Fry can be used as a command line utility, it is recommended to use Small-Fry as an API. \n",
    "\n",
    "First, import the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smallfry as sfry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space constraints:\n",
    "* We are going to use the default bitrate, R = 1, for compression.\n",
    "* If you have more space for your embeddings, be sure to give yourself a looser memory constraint!\n",
    "* You may specify either as an approximate memory budget (in bytes) or as a bitrate (avg bits per entry in embeddings matrix)\n",
    "* For most downstream applications, in order to incur <1% loss in extrinsic performance, the bitrate should be somewhere in (0.1,3). See TODO:paperlink for more details.\n",
    "\n",
    "Output directory:\n",
    "* You must specify an output directory using the param outdir. \n",
    "* The compressed embeddings will be written to this directory\n",
    "\n",
    "Prior:\n",
    "* The prior should be specified as word frequency counts over a corpus. Small-Fry automatically normalizes the frequency counts into a probability vector. \n",
    "* The prior should be a Python dictionary mapping word to float, saved in the `.npy` format. See [`numpy.save`](https://docs.scipy.org/doc/numpy-1.14.0/re)\n",
    "* Small-Fry is robust to noisy priors. If you do not have a prior of your own, and your application will be processing common English, please use [this prior], collected from the wiki16 corpus [cite]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making our call lets describe two variables we will need. Our `source_path` argument is 1000 lines out of the offical glove.6B.50d embeddings while our `prior_path` is a prior for these 1000 words in dict format saved as npy. We are now ready to make the API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Small-Fry representation to file: data/glove.head.sfry\n",
      "Compression complete!!!\n"
     ]
    }
   ],
   "source": [
    "word2idx, sfry_path  = sfry.compress(sourcepath=\"data/glove.head.txt\", \n",
    "                         priorpath=\"data/prior.npy\", \n",
    "                         outdir=\"data/glove.head.sfry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Small-Fry embeddings have been written to file!\n",
    "\n",
    "If we want to query them, let's load them into \n",
    "\n",
    "I bet you they're pretty small! Let's check the filesizes before and after!\n",
    "\n",
    "First, let's see how big the original embeddings are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428849 bytes\n"
     ]
    }
   ],
   "source": [
    "import os; print(str(os.path.getsize(\"data/glove.head.txt\")) + \" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's check out the size of the Small-Fry embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That's small!\n",
    "\n",
    "Now, let's see how we can efficiently query for word vectors without inflating the entire `.sfry` representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with other embeddings, the user is responsible for keeping track of the word representation returned by the Small-Fry compressor, in `word2idx`. Optionally, the word representation can be automatically saved by the `compress` call, using the `write-word-rep` flag.\n",
    "\n",
    "The path to Small-Fry's compressed embeddings is returned in `sfry_path`. Both of these returns are used in Small-Fry's `query` API call.\n",
    "\n",
    "We proceed to define the inputs for the querying:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to call the query routine on the word 'them':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But reading from disk can be slow! That's why Small-Fry can create a memory-mapped representation using `numpy.memmap`.\n",
    "\n",
    "Use `sfry.load` to generate a Python wrapper object as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8810.0\n"
     ]
    }
   ],
   "source": [
    "my_smallfry = sfry.load(sfry_path, word2idx) #generates a wrapper object for memory-mapped Small-Fry\n",
    "print(my_smallfry.get_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to query with your Small-Fry wrapper, just try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42144004  0.25169128 -0.45076984  0.09734009  0.33648273 -0.05103369\n",
      " -0.45076984 -0.18810399  0.02078924 -0.6736526   0.25169128 -0.11995012\n",
      " -0.55109245  0.17368607  0.02078924  0.02078924  0.09734009 -0.11995012\n",
      " -0.80504096 -0.11995012 -0.05103369 -0.3521969  -0.18810399 -0.2619221\n",
      " -0.18810399 -1.8357271  -0.80504096  0.09734009 -0.45076984 -0.18810399\n",
      "  4.0157175  -0.18810399 -0.55109245 -0.3521969   0.02078924  0.02078924\n",
      "  0.17368607 -0.18810399  0.02078924 -0.05103369 -0.2619221  -0.18810399\n",
      " -0.3521969  -0.05103369 -0.45076984  0.17368607  0.02078924 -0.18810399\n",
      " -0.11995012 -0.80504096]\n"
     ]
    }
   ],
   "source": [
    "print(my_smallfry.query(\"the\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is as easy as that! You are now ready to use Small-Fry embeddings for your favorite NLP apps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
